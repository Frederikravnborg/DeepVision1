{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03796647-01be-4cb7-af61-b6123f35389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Training simple_cnn...\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:14<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:15<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3477\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:16<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:15<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2717\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:18<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:15<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2460\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:15<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2407\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:18<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2282\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:15<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2360\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:16<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2381\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:13<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2524\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:15<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:17<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3089\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:15<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2782\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "Precision-Recall curve saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_simple_cnn.png\n",
      "Model saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\simple_cnn_best_weights.pth\n",
      "\n",
      "Training deep_cnn...\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:59<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3063\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:57<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2458\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:54<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2188\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:54<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2146\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:55<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1908\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:58<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2209\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:57<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1754\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:56<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1707\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:55<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1667\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:56<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1588\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:56<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1593\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:55<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1759\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:53<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2124\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:56<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:19<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1705\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:50<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1738\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "Precision-Recall curve saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_deep_cnn.png\n",
      "Model saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\deep_cnn_best_weights.pth\n",
      "\n",
      "Training resnet18...\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:20<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:17<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1421\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1001\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0942\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0801\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0952\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0840\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0829\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0862\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [01:19<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:18<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0807\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "Precision-Recall curve saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_resnet18.png\n",
      "Model saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\resnet18_best_weights.pth\n",
      "\n",
      "Training vgg16...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:13<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1668\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:13<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1285\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:17<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1215\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:15<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0963\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:15<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:25<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1151\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:16<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1026\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:13<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0912\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:15<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1009\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:11<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1177\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:11<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1025\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:08<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1019\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [03:11<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:24<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1148\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "Precision-Recall curve saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_vgg16.png\n",
      "Model saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\vgg16_best_weights.pth\n",
      "\n",
      "Training vit...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:12<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1290\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:04<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1087\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:07<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0951\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:14<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:28<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1019\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:06<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1048\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:26<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1117\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:09<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1040\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 1080/1080 [04:04<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 270/270 [00:27<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1256\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "Precision-Recall curve saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_vit.png\n",
      "Model saved to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\vit_best_weights.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from torchvision.models import vision_transformer\n",
    "# ===============================\n",
    "# Configuration and Parameters\n",
    "# ===============================\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = 'C:/Users/nicla/DTU/ComputerVision/3rd/Potholes'\n",
    "ANNOTATED_IMAGES_DIR = os.path.join(DATASET_DIR, 'annotated-images')\n",
    "TRAINING_DATA_FILE = os.path.join(DATASET_DIR, 'training_data.pkl')\n",
    "\n",
    "# Training Parameters\n",
    "NUM_CLASSES = 2  # 1 object class + 1 background\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50  # Maximum number of epochs\n",
    "LEARNING_RATE = 0.001\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "PATIENCE = 5  # Early stopping patience\n",
    "\n",
    "USE_FULL_DATA = True  # Use the full dataset or a reduced portion\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ===============================\n",
    "# Helper Functions\n",
    "# ===============================\n",
    "\n",
    "def save_precision_recall_curve(labels, probs, model_name):\n",
    "    \"\"\"\n",
    "    Saves the Precision-Recall curve for a model with higher resolution.\n",
    "    \n",
    "    Args:\n",
    "        labels (list): True labels.\n",
    "        probs (list): Predicted probabilities for the positive class.\n",
    "        model_name (str): Name of the model (used for saving the plot).\n",
    "    \"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(labels, probs)\n",
    "    average_precision = average_precision_score(labels, probs)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))  # Increase the figure size if needed\n",
    "    plt.plot(recall, precision, marker='.', label=f'AP = {average_precision:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve ({model_name})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot with higher resolution (300 dpi)\n",
    "    plot_save_path = os.path.join(DATASET_DIR, f'precision_recall_{model_name}.png')\n",
    "    plt.savefig(plot_save_path, dpi=300)  # Set dpi for high resolution\n",
    "    plt.close()\n",
    "    print(f'Precision-Recall curve saved to {plot_save_path}')\n",
    "    \n",
    "# ===============================\n",
    "# Task 1: Build the CNN\n",
    "# ===============================\n",
    "\n",
    "def build_model(model_type, num_classes):\n",
    "    if model_type == 'simple_cnn':\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "                self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "                self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "                self.fc2 = nn.Linear(128, num_classes)\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.relu = nn.ReLU()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.conv1(x)))\n",
    "                x = self.pool(self.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 32 * 56 * 56)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "\n",
    "        return SimpleCNN()\n",
    "    \n",
    "    elif model_type == 'deep_cnn':\n",
    "        class DeepCNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(DeepCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Increased channels\n",
    "                self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "                self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # More channels in deeper layers\n",
    "                self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)  # Additional convolutional layer\n",
    "                self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # Adjusted after more downsampling\n",
    "                self.fc2 = nn.Linear(1024, 512)\n",
    "                self.fc3 = nn.Linear(512, 128)\n",
    "                self.fc4 = nn.Linear(128, num_classes)  # Final classification layer\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
    "                self.batch_norm1 = nn.BatchNorm2d(64)  # Batch Normalization for stability\n",
    "                self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "                self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "                self.batch_norm4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.batch_norm1(self.conv1(x))))  # Conv -> Batch Norm -> ReLU -> Pool\n",
    "                x = self.pool(self.relu(self.batch_norm2(self.conv2(x))))\n",
    "                x = self.pool(self.relu(self.batch_norm3(self.conv3(x))))\n",
    "                x = self.pool(self.relu(self.batch_norm4(self.conv4(x))))\n",
    "                x = x.view(-1, 512 * 14 * 14)  # Flatten the output for fully connected layers\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.dropout(x)  # Apply dropout after dense layers\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.relu(self.fc3(x))\n",
    "                x = self.fc4(x)  # Output layer\n",
    "                return x\n",
    "\n",
    "        return DeepCNN()\n",
    "    \n",
    "    elif model_type == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        return model\n",
    "    \n",
    "    elif model_type == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        return model\n",
    "\n",
    "    elif model_type == 'vit':\n",
    "        # Use Vision Transformer (ViT) from torchvision\n",
    "        model = vision_transformer.vit_b_16(pretrained=True)  # Load the ViT model with pre-trained weights\n",
    "        \n",
    "        # Replace the classifier head with a custom linear layer\n",
    "        model.heads = nn.Sequential(\n",
    "            nn.Linear(model.heads[0].in_features, num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    else: raise ValueError(\"Unknown model type. Choose from 'simple_cnn', 'deep_cnn', 'resnet18', 'vgg16', 'vit'.\")\n",
    "\n",
    "# ===============================\n",
    "# Task 2: Create the DataLoader\n",
    "# ===============================\n",
    "\n",
    "class ProposalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Object Proposals.\n",
    "    \"\"\"\n",
    "    def __init__(self, proposals, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proposals (list): List of proposal dictionaries.\n",
    "            image_dir (str): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.proposals = proposals\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.proposals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        proposal = self.proposals[idx]\n",
    "        image_filename = proposal['image_filename']\n",
    "        bbox = proposal['bbox']\n",
    "        label = proposal['label']\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_dir, image_filename)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Crop the proposal region\n",
    "        cropped_image = image.crop((bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']))\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            cropped_image = self.transform(cropped_image)\n",
    "\n",
    "        return cropped_image, label\n",
    "\n",
    "def load_data(training_data_file):\n",
    "    \"\"\"\n",
    "    Loads the training data from a pickle file.\n",
    "    \"\"\"\n",
    "    with open(training_data_file, 'rb') as f:\n",
    "        combined_data = pickle.load(f)\n",
    "    proposals = combined_data['proposals']\n",
    "    ground_truths = combined_data['ground_truths']\n",
    "    return proposals, ground_truths\n",
    "\n",
    "# ===============================\n",
    "# Task 3: Fine-tune the Network\n",
    "# ===============================\n",
    "\n",
    "def train_model_with_early_stopping(model, criterion, optimizer, train_loader, val_loader, model_name, patience=PATIENCE):\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # For precision-recall calculation\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                all_probs.extend(probs)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "    # Load the best weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Save the precision-recall curve and model weights\n",
    "    save_precision_recall_curve(all_labels, all_probs, model_name)\n",
    "    model_save_path = os.path.join(DATASET_DIR, f'{model_name}_best_weights.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f'Model saved to {model_save_path}')\n",
    "    \n",
    "    return model\n",
    "# ===============================\n",
    "# Task 4: Evaluate the Model\n",
    "# ===============================\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluates the model's classification accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# ===============================\n",
    "# Visualization Function\n",
    "# ===============================\n",
    "\n",
    "def visualize_samples(model, subset, used_dataset, full_dataset, ground_truths, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualizes a few samples from the dataset with ground truth and predictions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        subset: Subset of the dataset (e.g., validation set).\n",
    "        used_dataset: The dataset used for training/validation (either full or reduced).\n",
    "        full_dataset: The original ProposalDataset.\n",
    "        ground_truths: Dictionary of ground truth boxes.\n",
    "        num_samples: Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples = random.sample(range(len(subset)), num_samples)\n",
    "\n",
    "    for idx in samples:\n",
    "        # Map subset index to original dataset index\n",
    "        if isinstance(used_dataset, Subset):\n",
    "            reduced_idx = used_dataset.indices[idx]\n",
    "        else:\n",
    "            reduced_idx = idx  # When using full dataset\n",
    "        proposal = full_dataset.proposals[reduced_idx]\n",
    "\n",
    "        image_filename = proposal['image_filename']\n",
    "        bbox = proposal['bbox']\n",
    "        label = proposal['label']\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(full_dataset.image_dir, image_filename)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        cropped_image = image.crop((bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']))\n",
    "\n",
    "        # Apply transforms\n",
    "        transform = full_dataset.transform\n",
    "        transformed_image = transform(cropped_image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            output = model(transformed_image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted = predicted.item()\n",
    "\n",
    "        # Convert image for plotting\n",
    "        image_np = transformed_image.squeeze(0).cpu().numpy()\n",
    "        image_np = np.transpose(image_np, (1, 2, 0))\n",
    "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "        # Plot the image\n",
    "        fig, ax = plt.subplots(1, figsize=(6, 6))\n",
    "        ax.imshow(image_np)\n",
    "        ax.axis('off')\n",
    "        title = f\"True Label: {'Object' if label == 1 else 'Background'} | Predicted: {'Object' if predicted == 1 else 'Background'}\"\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # Draw ground truth boxes (if available)\n",
    "        gt_boxes = ground_truths.get(image_filename, [])\n",
    "        for gt in gt_boxes:\n",
    "            rect = patches.Rectangle((gt['xmin'], gt['ymin']),\n",
    "                                     gt['xmax'] - gt['xmin'],\n",
    "                                     gt['ymax'] - gt['ymin'],\n",
    "                                     linewidth=2, edgecolor='green', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Main Execution\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    # Load data\n",
    "    proposals, ground_truths = load_data(TRAINING_DATA_FILE)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    full_dataset = ProposalDataset(proposals, ANNOTATED_IMAGES_DIR, transform=transform)\n",
    "    \n",
    "    if USE_FULL_DATA:\n",
    "        used_dataset = full_dataset\n",
    "    else:\n",
    "        total_samples = len(full_dataset)\n",
    "        reduced_sample_size = max(1, int(total_samples * 0.05))\n",
    "        sampled_indices = random.sample(range(total_samples), reduced_sample_size)\n",
    "        used_dataset = Subset(full_dataset, sampled_indices)\n",
    "\n",
    "    dataset_size = len(used_dataset)\n",
    "    val_size = int(dataset_size * VALIDATION_SPLIT)\n",
    "    train_size = dataset_size - val_size\n",
    "    train_dataset, val_dataset = random_split(used_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define the models to train\n",
    "    model_types = ['simple_cnn', 'deep_cnn', 'resnet18', 'vgg16', 'vit']\n",
    "    #model_types = ['vit']\n",
    "\n",
    "    for model_type in model_types:\n",
    "        print(f\"\\nTraining {model_type}...\\n\")\n",
    "        model = build_model(model_type, NUM_CLASSES).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        train_model_with_early_stopping(model, criterion, optimizer, train_loader, val_loader, model_name=model_type)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7825fd-7365-4257-b391-dd47bb21ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Evaluating model: deep_cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicla\\AppData\\Local\\Temp\\ipykernel_30948\\4278810516.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "Evaluating deep_cnn: 100%|█████████████████████████████████████████████████████████| 1350/1350 [01:30<00:00, 14.85it/s]\n",
      "C:\\Users\\nicla\\AppData\\Local\\Temp\\ipykernel_30948\\4278810516.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Precision-Recall curve for deep_cnn to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_deep_cnn_test.png\n",
      "Evaluating model: resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating resnet18: 100%|█████████████████████████████████████████████████████████| 1350/1350 [01:32<00:00, 14.67it/s]\n",
      "C:\\Users\\nicla\\AppData\\Local\\Temp\\ipykernel_30948\\4278810516.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Precision-Recall curve for resnet18 to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_resnet18_test.png\n",
      "Evaluating model: simple_cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating simple_cnn: 100%|███████████████████████████████████████████████████████| 1350/1350 [01:15<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Precision-Recall curve for simple_cnn to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_simple_cnn_test.png\n",
      "Evaluating model: vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicla\\AppData\\Local\\Temp\\ipykernel_30948\\4278810516.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "Evaluating vgg16: 100%|████████████████████████████████████████████████████████████| 1350/1350 [01:58<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Precision-Recall curve for vgg16 to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_vgg16_test.png\n",
      "Evaluating model: vit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\nicla\\AppData\\Local\\Temp\\ipykernel_30948\\4278810516.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "Evaluating vit: 100%|██████████████████████████████████████████████████████████████| 1350/1350 [02:12<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Precision-Recall curve for vit to C:/Users/nicla/DTU/ComputerVision/3rd/Potholes\\precision_recall_vit_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.ops import nms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "# ===============================\n",
    "# Paths and Configuration\n",
    "# ===============================\n",
    "\n",
    "DATASET_DIR = 'C:/Users/nicla/DTU/ComputerVision/3rd/Potholes'\n",
    "ANNOTATED_IMAGES_DIR = os.path.join(DATASET_DIR, 'annotated-images')\n",
    "TRAINING_DATA_FILE = os.path.join(DATASET_DIR, 'training_data.pkl')\n",
    "PROPOSALS_FILE = os.path.join(DATASET_DIR, 'selective_search_proposals_fast.json')\n",
    "SPLITS_FILE = os.path.join(DATASET_DIR, 'splits.json')\n",
    "MODELS_DIR = DATASET_DIR\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "IOU_THRESHOLD_NMS = 0.3\n",
    "IOU_THRESHOLD_EVAL = 0.5\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===============================\n",
    "# Helper Functions\n",
    "# ===============================\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a model based on its filename.\n",
    "    \"\"\"\n",
    "    if 'resnet18' in model_path:\n",
    "        model = models.resnet18()\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    elif 'vgg16' in model_path:\n",
    "        model = models.vgg16()\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    elif 'vit' in model_path:\n",
    "        model = models.vision_transformer.vit_b_16(pretrained=True)\n",
    "        model.heads = nn.Sequential(nn.Linear(model.heads[0].in_features, NUM_CLASSES))\n",
    "    elif 'deep_cnn' in model_path:\n",
    "        class DeepCNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(DeepCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Increased channels\n",
    "                self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "                self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # More channels in deeper layers\n",
    "                self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)  # Additional convolutional layer\n",
    "                self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # Adjusted after more downsampling\n",
    "                self.fc2 = nn.Linear(1024, 512)\n",
    "                self.fc3 = nn.Linear(512, 128)\n",
    "                self.fc4 = nn.Linear(128, NUM_CLASSES)  # Final classification layer\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
    "                self.batch_norm1 = nn.BatchNorm2d(64)  # Batch Normalization for stability\n",
    "                self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "                self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "                self.batch_norm4 = nn.BatchNorm2d(512)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.batch_norm1(self.conv1(x))))  # Conv -> Batch Norm -> ReLU -> Pool\n",
    "                x = self.pool(self.relu(self.batch_norm2(self.conv2(x))))\n",
    "                x = self.pool(self.relu(self.batch_norm3(self.conv3(x))))\n",
    "                x = self.pool(self.relu(self.batch_norm4(self.conv4(x))))\n",
    "                x = x.view(-1, 512 * 14 * 14)  # Flatten the output for fully connected layers\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.dropout(x)  # Apply dropout after dense layers\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.relu(self.fc3(x))\n",
    "                x = self.fc4(x)  # Output layer\n",
    "                return x\n",
    "\n",
    "        model = DeepCNN()\n",
    "    elif 'simple_cnn' in model_path:\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "                self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "                self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "                self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.relu = nn.ReLU()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.conv1(x)))\n",
    "                x = self.pool(self.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 32 * 56 * 56)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "\n",
    "        model = SimpleCNN()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type in {model_path}\")\n",
    "\n",
    "    # Load the model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    \"\"\"\n",
    "    Parse Pascal VOC XML annotations.\n",
    "    \"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        bndbox = obj.find('bndbox')\n",
    "        bbox = {\n",
    "            'xmin': int(float(bndbox.find('xmin').text)),\n",
    "            'ymin': int(float(bndbox.find('ymin').text)),\n",
    "            'xmax': int(float(bndbox.find('xmax').text)),\n",
    "            'ymax': int(float(bndbox.find('ymax').text))\n",
    "        }\n",
    "        boxes.append(bbox)\n",
    "    return boxes\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute IoU between two bounding boxes.\n",
    "    \"\"\"\n",
    "    x_left = max(box1['xmin'], box2['xmin'])\n",
    "    y_top = max(box1['ymin'], box2['ymin'])\n",
    "    x_right = min(box1['xmax'], box2['xmax'])\n",
    "    y_bottom = min(box1['ymax'], box2['ymax'])\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)\n",
    "    box1_area = (box1['xmax'] - box1['xmin'] + 1) * (box1['ymax'] - box1['ymin'] + 1)\n",
    "    box2_area = (box2['xmax'] - box2['xmin'] + 1) * (box2['ymax'] - box2['ymin'] + 1)\n",
    "    return intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "\n",
    "def apply_nms(detections, iou_threshold):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression (NMS) to detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    boxes = torch.tensor([d['bbox'] for d in detections], dtype=torch.float32)\n",
    "    scores = torch.tensor([d['score'] for d in detections], dtype=torch.float32)\n",
    "    keep_indices = nms(boxes, scores, iou_threshold)\n",
    "    return [detections[i] for i in keep_indices]\n",
    "\n",
    "def evaluate_model(model, dataloader, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate the model and generate Precision-Recall curve.\n",
    "    \"\"\"\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=f\"Evaluating {model_name}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = nn.functional.softmax(outputs, dim=1)[:, 1]\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    ap = average_precision_score(all_labels, all_probs)\n",
    "\n",
    "    # Save Precision-Recall curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f\"AP = {ap:.2f}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision-Recall Curve - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plot_save_path = os.path.join(DATASET_DIR, f\"precision_recall_{model_name}_test.png\")\n",
    "    plt.savefig(plot_save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved Precision-Recall curve for {model_name} to {plot_save_path}\")\n",
    "\n",
    "# ===============================\n",
    "# Main Execution\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    with open(TRAINING_DATA_FILE, 'rb') as f:\n",
    "        combined_data = pickle.load(f)\n",
    "    proposals = combined_data['proposals']\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    class ProposalDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, proposals, image_dir, transform=None):\n",
    "            self.proposals = proposals\n",
    "            self.image_dir = image_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.proposals)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            proposal = self.proposals[idx]\n",
    "            image_filename = proposal['image_filename']\n",
    "            bbox = proposal['bbox']\n",
    "            label = proposal['label']\n",
    "            image_path = os.path.join(self.image_dir, image_filename)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            cropped_image = image.crop((bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']))\n",
    "            if self.transform:\n",
    "                cropped_image = self.transform(cropped_image)\n",
    "            return cropped_image, label\n",
    "\n",
    "    dataset = ProposalDataset(proposals, ANNOTATED_IMAGES_DIR, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Evaluate all saved models\n",
    "    saved_models = [f for f in os.listdir(MODELS_DIR) if f.endswith(\"_best_weights.pth\")]\n",
    "    for model_file in saved_models:\n",
    "        model_path = os.path.join(MODELS_DIR, model_file)\n",
    "        model_name = model_file.replace(\"_best_weights.pth\", \"\")\n",
    "        print(f\"Evaluating model: {model_name}\")\n",
    "        model = load_model(model_path)\n",
    "        evaluate_model(model, dataloader, model_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf087533-4806-4a6b-aba2-1957e97e1b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
