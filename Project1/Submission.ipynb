{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f17d12-a25e-4dd7-8fa8-c94af4a79812",
   "metadata": {},
   "source": [
    "## Problem 2.1: Signal Processing as Linear Algebra\n",
    "\n",
    "We need to express the convolution operation between:\n",
    "- A discrete time signal $x_n$ of length $N$\n",
    "- An FIR filter of length $L$ with coefficients $θ_l$\n",
    "as a matrix product $y = X\\theta$\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Filter Coefficient Vector $\\theta$\n",
    "$\\theta$ is constructed as a column vector:\n",
    "\n",
    "$$\\theta = \\begin{bmatrix} \n",
    "θ_0 \\\\\n",
    "θ_1 \\\\\n",
    "\\vdots \\\\\n",
    "θ_{L-1}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "#### Input Signal Matrix $X$\n",
    "$X$ is constructed as a matrix where each row represents the signal values involved in one convolution operation:\n",
    "\n",
    "$$X = \\begin{bmatrix}\n",
    "x_0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "x_1 & x_0 & 0 & \\cdots & 0 \\\\\n",
    "x_2 & x_1 & x_0 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{N-1} & x_{N-2} & x_{N-3} & \\cdots & x_{N-L}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The dimensions of the matrices will be:\n",
    "- $X$: $(N) \\times (L)$ matrix\n",
    "- $\\theta$: $(L) \\times (1)$ vector\n",
    "- $y$: $(N) \\times (1)$ vector\n",
    "\n",
    "This construction ensures that each element of the output $y$ is computed as:\n",
    "\n",
    "$$y_n = \\sum_{l=0}^{L-1} x_{n-l}θ_l$$\n",
    "\n",
    "Which is equivalent to the convolution operation.\n",
    "\n",
    "## Problem 2.2: Biased vs Unbiased Parameter Estimation\n",
    "\n",
    "### Mean Square Error Decomposition\n",
    "\n",
    "Let's decompose the Mean Square Error (MSE) into bias and variance components.\n",
    "\n",
    "Definition:\n",
    "$$MSE = E[(ˆθ - θ_o)^2]$$\n",
    "\n",
    "Add and subtract $E[ˆθ]$ inside the squared term:\n",
    "$$MSE = E[(ˆθ - E[ˆθ] + E[ˆθ] - θ_o)^2]$$\n",
    "\n",
    "Expanding:\n",
    "$$MSE = E[(ˆθ - E[ˆθ])^2 + (E[ˆθ] - θ_o)^2 + 2(ˆθ - E[ˆθ])(E[ˆθ] - θ_o)]$$\n",
    "\n",
    "The cross term's expectation is zero:\n",
    "$$MSE = E[(ˆθ - E[ˆθ])^2] + (E[ˆθ] - θ_o)^2$$\n",
    "\n",
    "This gives us the final decomposition:\n",
    "$$MSE = \\underbrace{Var(ˆθ)}_{\\text{Variance}} + \\underbrace{(Bias(ˆθ,θ_o))^2}_{\\text{Squared Bias}}$$\n",
    "\n",
    "### Analysis of Biased vs Unbiased Estimators\n",
    "\n",
    "For minimizing MSE:\n",
    "\n",
    "1. **Unbiased Estimators**:\n",
    "   - Have $Bias(ˆθ,θ_o) = 0$\n",
    "   - MSE equals variance: $MSE = Var(ˆθ)$\n",
    "   - Often have higher variance to maintain unbiasedness\n",
    "\n",
    "2. **Biased Estimators**:\n",
    "   - Have non-zero bias but potentially lower variance\n",
    "   - Can achieve lower MSE despite bias\n",
    "   - Examples like Ridge Regression deliberately introduce bias to reduce variance\n",
    "\n",
    "#### Conclusion\n",
    "A biased estimator is often better suited for minimizing MSE because:\n",
    "1. It can achieve a better trade-off between bias and variance\n",
    "2. Small bias is often acceptable if it leads to substantial variance reduction\n",
    "3. In practice, the total MSE is what matters for prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc74d1c-363e-4efd-bbae-67003469f107",
   "metadata": {},
   "source": [
    "## Problem 2.3: All Norms are Convex Functions\n",
    "\n",
    "## Setup and Definitions\n",
    "\n",
    "1. **Norm Definition**: A norm $\\|\\cdot\\|$ on a vector space $V$ satisfies:\n",
    "   - Positive definiteness: $\\|x\\| \\geq 0$ and $\\|x\\| = 0$ iff $x = 0$\n",
    "   - Homogeneity: $\\|αx\\| = |α|\\|x\\|$ for all scalars $α$\n",
    "   - Triangle inequality: $\\|x + y\\| \\leq \\|x\\| + \\|y\\|$\n",
    "\n",
    "2. **Convexity Definition**: A function $f$ is convex if for any two points $x_1, x_2$ and any $t \\in [0,1]$:\n",
    "   $$f(tx_1 + (1-t)x_2) \\leq tf(x_1) + (1-t)f(x_2)$$\n",
    "\n",
    "## Proof\n",
    "\n",
    "\n",
    "- Take any two points $x_1, x_2$ in the vector space\n",
    "- Take any $t \\in [0,1]$\n",
    "\n",
    "### Apply Triangle Inequality\n",
    "Start with the left side of the convexity inequality:\n",
    "$$\\|tx_1 + (1-t)x_2\\|$$\n",
    "\n",
    "### Apply Homogeneity\n",
    "$$\\|tx_1 + (1-t)x_2\\| = \\|t(x_1) + (1-t)(x_2)\\|$$\n",
    "\n",
    "### Apply Triangle Inequality\n",
    "$$\\|t(x_1) + (1-t)(x_2)\\| \\leq \\|t(x_1)\\| + \\|(1-t)(x_2)\\|$$\n",
    "\n",
    "### Apply Homogeneity Again\n",
    "$$\\|t(x_1)\\| + \\|(1-t)(x_2)\\| = |t|\\|x_1\\| + |1-t|\\|x_2\\|$$\n",
    "\n",
    "### SSimplify\n",
    "Since $t \\in [0,1]$:\n",
    "- $|t| = t$\n",
    "- $|1-t| = 1-t$\n",
    "\n",
    "Therefore:\n",
    "$$|t|\\|x_1\\| + |1-t|\\|x_2\\| = t\\|x_1\\| + (1-t)\\|x_2\\|$$\n",
    "\n",
    "### Final Result\n",
    "Putting it all together:\n",
    "$$\\|tx_1 + (1-t)x_2\\| \\leq t\\|x_1\\| + (1-t)\\|x_2\\|$$\n",
    "\n",
    "This is exactly the definition of convexity for the norm function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a8a99-d055-49b5-bc62-f08432f07cd4",
   "metadata": {},
   "source": [
    "## Problem 2.4 Correlation functions\n",
    "\n",
    "Given:\n",
    "- AR(1) process: $x_n = ax_{n-1} + v_n$\n",
    "- New signal: $y_n = x_n + b$\n",
    "- Conditions:\n",
    "  - $a \\in ]-1,1[$ (AR coefficient)\n",
    "  - $v_n$ is white noise with variance $σ^2_v$\n",
    "  - $E[x_n] = 0$\n",
    "  - $b \\in \\mathbb{R}$\n",
    "\n",
    "\n",
    "For an AR(1) process with $E[x_n] = 0$:\n",
    "1. Variance of $x_n$: $σ^2_x = \\frac{σ^2_v}{1-a^2}$\n",
    "2. Auto-correlation function of $x_n$: $r_x(k) = σ^2_x a^{|k|}$\n",
    "\n",
    "## Computing $E[y_n]$\n",
    "\n",
    "$$\\begin{align*}\n",
    "E[y_n] &= E[x_n + b] = 0 + b = b\n",
    "\\end{align*}$$\n",
    "\n",
    "## Deriving Auto-correlation Function $r_y(k)$\n",
    "\n",
    "The auto-correlation function for $y_n$ is:\n",
    "$$r_y(k) = E[(y_n - E[y_n])(y_{n-k} - E[y_{n-k}])]$$\n",
    "\n",
    "Substituting:\n",
    "$$\\begin{align*}\n",
    "r_y(k) &= E[(x_n + b - b)(x_{n-k} + b - b)] = E[x_n x_{n-k}] = r_x(k) = σ^2_x a^{|k|} = \\frac{σ^2_v}{1-a^2} a^{|k|}\n",
    "\\end{align*}$$\n",
    "\n",
    "## Computing $r_y(-2)$ for Given Values\n",
    "\n",
    "Given:\n",
    "$a = 0.8$, $b = 0.5$, $σ^2_v = 1$\n",
    "\n",
    "First, compute $σ^2_x$:\n",
    "$$σ^2_x = \\frac{σ^2_v}{1-a^2} = \\frac{1}{1-0.8^2} = \\frac{1}{1-0.64} = \\frac{1}{0.36} = 2.778$$\n",
    "\n",
    "Then, compute $r_y(-2)$:\n",
    "$$\\begin{align*}\n",
    "r_y(-2) &= σ^2_x a^{|−2|} = 2.778 \\times (0.8)^2 = 2.778 \\times 0.64 = 1.778\n",
    "\\end{align*}$$\n",
    "\n",
    "The auto-correlation function for signal $y_n$ is:\n",
    "$$r_y(k) = \\frac{σ^2_v}{1-a^2} a^{|k|}$$\n",
    "\n",
    "For the given values:\n",
    "$$r_y(-2) = 1.778$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2525c9-6085-4349-b0d0-ec25c0106c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
